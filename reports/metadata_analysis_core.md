# Comprehensive Metadata Analysis Report (CORE)

Generated by `tools/analyze_metadata.py`

This consolidated report analyzes metadata coverage, quality, and filtering capabilities.

**Consolidates:**
- General metadata exploration (formerly `inspect_metadata.py`)
- Game-specific filtering analysis (formerly `analyze_game_metadata.py`)
- Label coverage analysis (formerly `report_label_statistics_built.py`)

---

**Total entries:** 208,201

---

## Frequency Tier Distribution

| Tier | Count | Percentage |
|------|------:|-----------:|
| rare | 174,953 | 84.0% |
| top10 | 6 | 0.0% |
| top100 | 86 | 0.0% |
| top10k | 5,803 | 2.8% |
| top1k | 474 | 0.2% |
| top25k | 10,897 | 5.2% |
| top300 | 190 | 0.1% |
| top3k | 1,841 | 0.9% |
| top500 | 196 | 0.1% |
| top50k | 13,755 | 6.6% |

### Sample Words by Tier

**Tier rare:** `vasectomize`, `concretes`, `antiradicalisms`, `imprecisenesses`, `guyed`  
**Tier top10:** `it`, `you`, `and`, `that`, `the`  
**Tier top100:** `what`, `right`, `as`, `are`, `come`  
**Tier top10k:** `essay`, `faint`, `references`, `steer`, `approaches`  
**Tier top1k:** `ones`, `date`, `serious`, `realize`, `seeing`  

---

## Source Distribution

### Individual Sources

| Source | Words |
|--------|------:|
| enable | 172,823 |
| eowl | 128,983 |

### Source Combinations

| Sources | Words |
|---------|------:|
| enable, eowl | 93,605 |
| enable | 79,218 |
| eowl | 35,378 |

---

## Label Coverage Analysis

**Metadata coverage summary:**

| Metadata Type | Entries | Percentage |
|--------------|--------:|-----------:|
| POS tags | 109,383 | 52.5% |
| Any labels | 0 | 0.0% |
| Register labels | 0 | 0.0% |
| Domain labels | 0 | 0.0% |
| Region labels | 0 | 0.0% |
| Temporal labels | 0 | 0.0% |

*Note: POS tags are stored separately from labels in the metadata.*

### Part of Speech Tags

| POS | Count |
|-----|------:|
| noun | 71,862 |
| verb | 31,922 |
| adjective | 17,665 |
| adverb | 3,466 |

---

## Game-Specific Metadata Analysis

This section analyzes metadata coverage for word game filtering needs.

### Field Coverage

**Total entries:** 208,201

| Field | Coverage | Percentage |
|-------|------:|----------:|
| POS tags | 109,383 | 52.5% |
| Concreteness | 71,860 | 34.5% |
| Frequency tier | 208,201 | 100.0% |
| Labels | 0 | 0.0% |
| Gloss | 0 | 0.0% |

### Noun Analysis

**Total nouns:** 71,862
**Concrete nouns:** 20,670
**Abstract nouns:** 25,782
**Mixed nouns:** 25,408
**Nouns without concreteness data:** 2

⚠️  **0.0%** of nouns lack concreteness metadata!

#### Concreteness Distribution

| Type | Count |
|------|------:|
| abstract | 25,782 |
| mixed | 25,408 |
| concrete | 20,670 |
| unknown | 2 |

#### Frequency Distribution (Nouns Only)

| Tier | Count |
|------|------:|
| top10 | 1 |
| top100 | 48 |
| top1k | 354 |
| top10k | 4,126 |
| top100k | 0 |
| rare | 50,680 |

---

## Sense-Based Format Analysis

### Current Limitations

The current format merges all senses of a word into a single entry:

**Issues:**
- Words with multiple POS (e.g., 'crow' as noun and verb) lose sense-specific metadata
- Regional variants (e.g., 'colour' vs 'color') are not linked
- Sense-specific labels (e.g., offensive meaning vs. neutral meaning) are conflated
- Downstream filtering cannot distinguish between word senses

**Statistics:**
- **14,647** words have multiple POS tags (potential for sense splitting)
- **0** words have regional labels

### Proposed Sense-Based Format

Each sense of a word becomes its own entry with a sense ID:

```
word    sense_id    metadata_fields
crow    crow.n.1    pos:noun|sem:animal|sem:bird|domain:zoology|concrete:yes|freq:top3k
crow    crow.n.2    pos:noun|sem:person|register:derogatory|register:offensive|temporal:historical
crow    crow.v.1    pos:verb|sem:sound|sem:vocalize|concrete:no|freq:top10k
mummy   mummy.n.1   pos:noun|sem:artifact|sem:corpse|domain:archaeology|concrete:yes
mummy   mummy.n.2   pos:noun|sem:person|sem:parent|register:informal|region:en-GB|freq:top5k
colour  colour.n.1  pos:noun|sem:attribute|sem:visual|region:en-GB|freq:top1k|variant:color
color   color.n.1   pos:noun|sem:attribute|sem:visual|region:en-US|freq:top1k|variant:colour
```

### Benefits

1. **Precise filtering:** Filter out offensive senses while keeping neutral ones
2. **Regional handling:** Link variant spellings, choose preferred region
3. **Semantic richness:** Add semantic tags (animal, person, sound, etc.)
4. **Game optimization:** Include only common senses, exclude rare technical senses
5. **Frequency per sense:** Different senses may have different frequencies

### Implementation Path

1. **Extract sense-level data from Wiktionary**
   - Current scanner merges all senses - needs modification
   - Parse each sense separately with its own labels, glosses, etc.

2. **Generate sense IDs**
   - Format: `{word}.{pos_abbrev}.{sense_num}`
   - Example: `crow.n.1`, `crow.v.1`
   - Handle multi-word phrases with URL encoding if needed

3. **Add semantic tags**
   - Extract from Wiktionary glosses using NLP
   - Use WordNet hypernyms (animal, person, object, etc.)
   - Manual curation for high-frequency words

4. **Link variants**
   - Track US/UK spelling pairs
   - Include `variant:` field pointing to alternate spellings

5. **Downstream processing**
   - Filters can target specific senses
   - Final word lists can collapse senses or keep them separate
   - Enables sophisticated game-specific word selection

### Example Filtering Queries

```bash
# Get only concrete nouns (any sense)
grep '|concrete:yes' senses.txt | cut -f1 | sort -u

# Get common words excluding offensive senses
grep '|freq:top' senses.txt | grep -v '|register:offensive' | cut -f1 | sort -u

# Get US-preferred spellings
grep '|region:en-US' senses.txt | cut -f1 | sort -u

# Get animal words
grep '|sem:animal' senses.txt | cut -f1 | sort -u
```

### Sample Multi-POS Words

Examples of words that would benefit from sense splitting:

- **abandon**: noun, verb
- **abandoned**: adjective, verb
- **abandons**: noun, verb
- **abashed**: adjective, verb
- **abbreviated**: adjective, verb
- **abdominal**: adjective, noun
- **abducent**: adjective, noun
- **abducting**: adjective, verb
- **abecedarian**: adjective, noun
- **aberrant**: adjective, noun

---

## Filtering Recommendations

### ⚠️ CRITICAL: Label Data Loss Detected

Only 0 entries have labels in the final distribution.
This indicates a pipeline issue where labels are being dropped during build.

**Action required:**
1. Investigate build pipeline for label preservation
2. Check intermediate files to identify where labels are lost
3. Fix label extraction and/or merging logic

### 2. Domain-Based Filtering

⚠️ Domain labels not available - fix pipeline first

### 3. Frequency-Based Ranking

Prioritize common words (top10k tier) that people actually use:
- **Kids' games:** top1k to top10k
- **General games:** top100 to top100k
- **Expert games:** Include rare words

### 5. Manual Review Process

Even with good filters, manual review is essential:
- Review top 500-1000 candidates
- Create whitelist of verified words
- Create blacklist of inappropriate words
- Use lists to train better filters

---

## Sample Rich Entries

These entries have extensive metadata (multiple sources, labels, glosses, etc.)

