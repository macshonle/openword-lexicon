#!/usr/bin/env python3
"""
inspect_phrases.py - Analyze phrase length distribution in wordlist

Helps determine appropriate thresholds for filtering out long
multi-word phrases while retaining useful idioms.
"""
import sys
from pathlib import Path
from collections import Counter
from typing import List, Tuple


def analyze_wordlist(filepath: Path) -> dict:
    """Analyze phrase/word length distribution."""
    if not filepath.exists():
        return {'error': f'File not found: {filepath}'}

    with open(filepath, 'r', encoding='utf-8') as f:
        words = [line.strip() for line in f if line.strip()]

    # Count distribution
    word_count_dist = Counter()  # Number of space-separated words
    char_length_dist = Counter()  # Character length

    by_word_count = {}  # Examples at each word count
    by_char_length = {}  # Examples at each char length

    for word in words:
        word_count = word.count(' ') + 1
        char_length = len(word)

        word_count_dist[word_count] += 1
        char_length_dist[char_length] += 1

        # Store examples
        if word_count not in by_word_count:
            by_word_count[word_count] = []
        if len(by_word_count[word_count]) < 10:
            by_word_count[word_count].append(word)

        if char_length not in by_char_length:
            by_char_length[char_length] = []
        if len(by_char_length[char_length]) < 5:
            by_char_length[char_length].append(word)

    return {
        'total': len(words),
        'word_count_dist': word_count_dist,
        'char_length_dist': char_length_dist,
        'by_word_count': by_word_count,
        'by_char_length': by_char_length,
    }


def generate_report(distribution: str = 'plus'):
    """Generate phrase analysis report."""
    filepath = Path(f'data/build/{distribution}/wordlist.txt')

    report = f"# Phrase Analysis Report ({distribution.upper()})\n\n"
    report += f"Generated by `tools/inspect_phrases.py`\n\n"
    report += "Analyzes multi-word phrases and their lengths to help determine filtering thresholds.\n\n"
    report += "---\n\n"

    analysis = analyze_wordlist(filepath)

    if 'error' in analysis:
        report += f"## Error\n\n{analysis['error']}\n"
        print(report)
        return

    total = analysis['total']
    word_count_dist = analysis['word_count_dist']
    char_length_dist = analysis['char_length_dist']

    # Word count distribution
    report += "## Distribution by Word Count\n\n"
    report += "| Words | Count | Percentage | Cumulative % |\n"
    report += "|------:|------:|-----------:|-------------:|\n"

    cumulative = 0
    for word_count in sorted(word_count_dist.keys()):
        count = word_count_dist[word_count]
        pct = (count / total * 100)
        cumulative += pct
        report += f"| {word_count} | {count:,} | {pct:.2f}% | {cumulative:.2f}% |\n"

    report += "\n### Examples by Word Count\n\n"

    for word_count in sorted(analysis['by_word_count'].keys())[:15]:
        examples = analysis['by_word_count'][word_count]
        count = word_count_dist[word_count]
        report += f"**{word_count} word{'s' if word_count > 1 else ''}** ({count:,} entries):\n"
        report += "- " + "\n- ".join(f"`{ex}`" for ex in examples) + "\n\n"

    # Character length analysis
    report += "\n---\n\n## Distribution by Character Length\n\n"

    # Group by ranges
    ranges = [(1, 10), (11, 20), (21, 30), (31, 40), (41, 50), (51, 100), (101, 150)]

    report += "| Length Range | Count | Percentage |\n"
    report += "|--------------|------:|-----------:|\n"

    for start, end in ranges:
        count = sum(char_length_dist[l] for l in range(start, end + 1) if l in char_length_dist)
        pct = (count / total * 100) if total > 0 else 0
        report += f"| {start}-{end} chars | {count:,} | {pct:.2f}% |\n"

    # Show examples of very long entries
    report += "\n### Longest Entries\n\n"

    long_entries = []
    for char_length in sorted(analysis['by_char_length'].keys(), reverse=True)[:20]:
        for word in analysis['by_char_length'][char_length]:
            long_entries.append((char_length, word))

    for char_length, word in long_entries[:20]:
        word_count = word.count(' ') + 1
        report += f"**{char_length} chars, {word_count} words:** `{word}`\n\n"

    # Suggested thresholds
    report += "\n---\n\n## Suggested Filter Thresholds\n\n"

    thresholds = [
        (3, "Keep up to 3-word phrases (idioms like 'kick the bucket')"),
        (4, "Keep up to 4-word phrases (idioms + short expressions)"),
        (5, "Keep up to 5-word phrases (includes longer expressions)"),
        (40, "Filter by character length ≤40 (removes proverbs)"),
        (50, "Filter by character length ≤50 (removes long sayings)"),
    ]

    for threshold, description in thresholds:
        if threshold <= 5:  # Word count
            kept = sum(word_count_dist[wc] for wc in word_count_dist if wc <= threshold)
        else:  # Character length
            kept = sum(char_length_dist[cl] for cl in char_length_dist if cl <= threshold)

        kept_pct = (kept / total * 100)
        removed = total - kept
        removed_pct = (removed / total * 100)

        report += f"### {description}\n\n"
        report += f"- **Keep:** {kept:,} entries ({kept_pct:.2f}%)\n"
        report += f"- **Remove:** {removed:,} entries ({removed_pct:.2f}%)\n\n"

    # Write report
    output_path = Path(f'reports/phrase_analysis_{distribution}.md')
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"Phrase analysis report ({distribution}) written to {output_path}")
    return output_path


if __name__ == '__main__':
    distribution = sys.argv[1] if len(sys.argv) > 1 else 'plus'

    if distribution not in ['core', 'plus']:
        print(f"Error: distribution must be 'core' or 'plus', got '{distribution}'")
        sys.exit(1)

    generate_report(distribution)
